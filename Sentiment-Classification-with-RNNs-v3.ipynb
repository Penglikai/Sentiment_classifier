{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sentiment Classification Using RNNs \n",
    "\n",
    "### In this example, we see sentiment classification.\n",
    "### Intead of an Elman RNN built using the RNNCell, use built-in RNNs: nn.RNN, nn.LSTM, and nn.GRU.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from argparse import Namespace\n",
    "import os\n",
    "import json\n",
    "from collections import Counter\n",
    "import string\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.nn.utils.rnn import pack_padded_sequence, pad_packed_sequence\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vocabulary, Vectorizer, Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Vocabulary(object):\n",
    "    \"\"\"Class to process text and extract vocabulary for mapping\"\"\"\n",
    "\n",
    "    def __init__(self, token_to_idx=None):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            token_to_idx (dict): a pre-existing map of tokens to indices\n",
    "        \"\"\"\n",
    "\n",
    "        if token_to_idx is None:\n",
    "            token_to_idx = {}\n",
    "        self._token_to_idx = token_to_idx\n",
    "\n",
    "        self._idx_to_token = {idx: token \n",
    "                              for token, idx in self._token_to_idx.items()}\n",
    "        \n",
    "    def to_serializable(self):\n",
    "        \"\"\" returns a dictionary that can be serialized \"\"\"\n",
    "        return {'token_to_idx': self._token_to_idx}\n",
    "\n",
    "    @classmethod\n",
    "    def from_serializable(cls, contents):\n",
    "        \"\"\" instantiates the Vocabulary from a serialized dictionary \"\"\"\n",
    "        return cls(**contents)\n",
    "\n",
    "    def add_token(self, token):\n",
    "        \"\"\"Update mapping dicts based on the token.\n",
    "\n",
    "        Args:\n",
    "            token (str): the item to add into the Vocabulary\n",
    "        Returns:\n",
    "            index (int): the integer corresponding to the token\n",
    "        \"\"\"\n",
    "        if token in self._token_to_idx:\n",
    "            index = self._token_to_idx[token]\n",
    "        else:\n",
    "            index = len(self._token_to_idx)\n",
    "            self._token_to_idx[token] = index\n",
    "            self._idx_to_token[index] = token\n",
    "        return index\n",
    "            \n",
    "    def add_many(self, tokens):\n",
    "        \"\"\"Add a list of tokens into the Vocabulary\n",
    "        \n",
    "        Args:\n",
    "            tokens (list): a list of string tokens\n",
    "        Returns:\n",
    "            indices (list): a list of indices corresponding to the tokens\n",
    "        \"\"\"\n",
    "        return [self.add_token(token) for token in tokens]\n",
    "\n",
    "    def lookup_token(self, token):\n",
    "        \"\"\"Retrieve the index associated with the token \n",
    "        \n",
    "        Args:\n",
    "            token (str): the token to look up \n",
    "        Returns:\n",
    "            index (int): the index corresponding to the token\n",
    "        \"\"\"\n",
    "        return self._token_to_idx[token]\n",
    "\n",
    "    def lookup_index(self, index):\n",
    "        \"\"\"Return the token associated with the index\n",
    "        \n",
    "        Args: \n",
    "            index (int): the index to look up\n",
    "        Returns:\n",
    "            token (str): the token corresponding to the index\n",
    "        Raises:\n",
    "            KeyError: if the index is not in the Vocabulary\n",
    "        \"\"\"\n",
    "        if index not in self._idx_to_token:\n",
    "            raise KeyError(\"the index (%d) is not in the Vocabulary\" % index)\n",
    "        return self._idx_to_token[index]\n",
    "\n",
    "    def __str__(self):\n",
    "        return \"<Vocabulary(size=%d)>\" % len(self)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self._token_to_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SequenceVocabulary(Vocabulary):\n",
    "    def __init__(self, token_to_idx=None, unk_token=\"<UNK>\",\n",
    "                 mask_token=\"<MASK>\", begin_seq_token=\"<BEGIN>\",\n",
    "                 end_seq_token=\"<END>\"):\n",
    "\n",
    "        super(SequenceVocabulary, self).__init__(token_to_idx)\n",
    "\n",
    "        self._mask_token = mask_token\n",
    "        self._unk_token = unk_token\n",
    "        self._begin_seq_token = begin_seq_token\n",
    "        self._end_seq_token = end_seq_token\n",
    "\n",
    "        self.mask_index = self.add_token(self._mask_token)\n",
    "        self.unk_index = self.add_token(self._unk_token)\n",
    "        self.begin_seq_index = self.add_token(self._begin_seq_token)\n",
    "        self.end_seq_index = self.add_token(self._end_seq_token)\n",
    "\n",
    "    def to_serializable(self):\n",
    "        contents = super(SequenceVocabulary, self).to_serializable()\n",
    "        contents.update({'unk_token': self._unk_token,\n",
    "                         'mask_token': self._mask_token,\n",
    "                         'begin_seq_token': self._begin_seq_token,\n",
    "                         'end_seq_token': self._end_seq_token})\n",
    "        return contents\n",
    "\n",
    "    def lookup_token(self, token):\n",
    "        \"\"\"Retrieve the index associated with the token \n",
    "          or the UNK index if token isn't present.\n",
    "        \n",
    "        Args:\n",
    "            token (str): the token to look up \n",
    "        Returns:\n",
    "            index (int): the index corresponding to the token\n",
    "        Notes:\n",
    "            `unk_index` needs to be >=0 (having been added into the Vocabulary) \n",
    "              for the UNK functionality \n",
    "        \"\"\"\n",
    "        if self.unk_index >= 0:\n",
    "            return self._token_to_idx.get(token, self.unk_index)\n",
    "        else:\n",
    "            return self._token_to_idx[token]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ReviewVectorizer(object):\n",
    "    \"\"\" The Vectorizer which coordinates the Vocabularies and puts them to use\"\"\"   \n",
    "    def __init__(self, review_vocab, rating_vocab, max_sequnce_length):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            review_vocab (Vocabulary): maps words to integers\n",
    "            rating_vocab (Vocabulary): maps class labels to integers; {'negative':0, 'positive':1}\n",
    "        \"\"\"\n",
    "        self.review_vocab = review_vocab\n",
    "        self.rating_vocab = rating_vocab\n",
    "        self.max_sequnce_length = max_sequnce_length\n",
    "\n",
    "    def vectorize(self, review, vector_length=-1):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            review (str): the string of words\n",
    "            vector_length (int): an argument for forcing the length of index vector\n",
    "        \"\"\"\n",
    "        indices = [self.review_vocab.begin_seq_index]       \n",
    "                \n",
    "        for token in review.split(\" \"):\n",
    "            if token not in string.punctuation:\n",
    "                indices.append(self.review_vocab.lookup_token(token))\n",
    "\n",
    "        indices.append(self.review_vocab.end_seq_index)\n",
    "\n",
    "        if vector_length < 0:\n",
    "            vector_length = len(indices)\n",
    "\n",
    "        out_vector = np.zeros(vector_length, dtype=np.int64)         \n",
    "        out_vector[:len(indices)] = indices\n",
    "        out_vector[len(indices):] = self.review_vocab.mask_index\n",
    "        \n",
    "        return out_vector, len(indices)\n",
    "\n",
    "    @classmethod\n",
    "    def from_dataframe(cls, review_df, cutoff=2):\n",
    "        \"\"\"Instantiate the vectorizer from the dataset dataframe\n",
    "        \n",
    "        Args:\n",
    "            review_df (pandas.DataFrame): the surnames dataset\n",
    "        Returns:\n",
    "            an instance of the ReviewVectorizer\n",
    "        \"\"\"\n",
    "        review_vocab = SequenceVocabulary()\n",
    "        rating_vocab = Vocabulary()\n",
    "        \n",
    "        max_sequnce_length = 0\n",
    "        \n",
    "        # Add ratings\n",
    "        for rating in sorted(set(review_df.rating)):\n",
    "            rating_vocab.add_token(rating)\n",
    "\n",
    "        \n",
    "        # Add top words if count > provided count\n",
    "        word_counts = Counter()\n",
    "        for review in review_df.review:\n",
    "            tokens = review.split(\" \")\n",
    "            if len(tokens) > max_sequnce_length:\n",
    "                max_sequnce_length = len(tokens) \n",
    "            for word in tokens:\n",
    "                if word not in string.punctuation:\n",
    "                    word_counts[word] += 1\n",
    "               \n",
    "        for word, count in word_counts.items():\n",
    "            if count > cutoff:\n",
    "                review_vocab.add_token(word)\n",
    "\n",
    "        return cls(review_vocab, rating_vocab, max_sequnce_length)   \n",
    "\n",
    "    @classmethod\n",
    "    def from_serializable(cls, contents):\n",
    "        review_vocab = SequenceVocabulary.from_serializable(contents['review_vocab'])\n",
    "        rating_vocab =  Vocabulary.from_serializable(contents['rating_vocab'])\n",
    "\n",
    "        return cls(review_vocab=review_vocab, rating_vocab=rating_vocab)\n",
    "\n",
    "    def to_serializable(self):\n",
    "        return {'review_vocab': self.review_vocab.to_serializable(), \n",
    "                'rating_vocab': self.rating_vocab.to_serializable()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ReviewDataset(Dataset):\n",
    "    def __init__(self, review_df, vectorizer):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            review_df (pandas.DataFrame): the dataset\n",
    "            vectorizer (ReviewVectorizer): vectorizer instatiated from dataset\n",
    "        \"\"\"\n",
    "        self.review_df = review_df \n",
    "        self._vectorizer = vectorizer\n",
    "\n",
    "        self._max_seq_length = self._vectorizer.max_sequnce_length + 2   # add 2 for begin_seq_token and end_seq_token\n",
    "\n",
    "        self.train_df = self.review_df[self.review_df.split=='train']\n",
    "        self.train_size = len(self.train_df)\n",
    "\n",
    "        self.val_df = self.review_df[self.review_df.split=='val']\n",
    "        self.validation_size = len(self.val_df)\n",
    "\n",
    "        self.test_df = self.review_df[self.review_df.split=='test']\n",
    "        self.test_size = len(self.test_df)\n",
    "\n",
    "        self._lookup_dict = {'train': (self.train_df, self.train_size), \n",
    "                             'val': (self.val_df, self.validation_size), \n",
    "                             'test': (self.test_df, self.test_size)}\n",
    "\n",
    "        self.set_split('train')\n",
    "        \n",
    "        # Class weights\n",
    "        class_counts = self.train_df.rating.value_counts().to_dict()\n",
    "        def sort_key(item):\n",
    "            return self._vectorizer.rating_vocab.lookup_token(item[0])\n",
    "        sorted_counts = sorted(class_counts.items(), key=sort_key)\n",
    "        frequencies = [count for _, count in sorted_counts]\n",
    "        self.class_weights = 1.0 / torch.tensor(frequencies, dtype=torch.float32)\n",
    "\n",
    "        \n",
    "    @classmethod\n",
    "    def load_dataset_and_make_vectorizer(cls, review_csv):\n",
    "        \"\"\"Load dataset and make a new vectorizer from scratch\n",
    "        \n",
    "        Args:\n",
    "            review_csv (str): location of the dataset\n",
    "        Returns:\n",
    "            an instance of ReviewDataset\n",
    "        \"\"\"\n",
    "        review_df = pd.read_csv(review_csv)\n",
    "        train_review_df = review_df[review_df.split=='train']\n",
    "        return cls(review_df, ReviewVectorizer.from_dataframe(train_review_df))\n",
    "        \n",
    "    @classmethod\n",
    "    def load_dataset_and_load_vectorizer(cls, review_csv, vectorizer_filepath):\n",
    "        \"\"\"Load dataset and the corresponding vectorizer. \n",
    "        Used in the case in the vectorizer has been cached for re-use\n",
    "        \n",
    "        Args:\n",
    "            review_csv (str): location of the dataset\n",
    "            vectorizer_filepath (str): location of the saved vectorizer\n",
    "        Returns:\n",
    "            an instance of ReviewDataset\n",
    "        \"\"\"\n",
    "        review_df = pd.read_csv(review_csv)\n",
    "        vectorizer = cls.load_vectorizer_only(vectorizer_filepath)\n",
    "        return cls(review_df, vectorizer)\n",
    "\n",
    "    @staticmethod\n",
    "    def load_vectorizer_only(vectorizer_filepath):\n",
    "        \"\"\"a static method for loading the vectorizer from file\n",
    "        \n",
    "        Args:\n",
    "            vectorizer_filepath (str): the location of the serialized vectorizer\n",
    "        Returns:\n",
    "            an instance of ReviewVectorizer\n",
    "        \"\"\"\n",
    "        with open(vectorizer_filepath) as fp:\n",
    "            return ReviewVectorizer.from_serializable(json.load(fp))\n",
    "\n",
    "    def save_vectorizer(self, vectorizer_filepath):\n",
    "        \"\"\"saves the vectorizer to disk using json\n",
    "        \n",
    "        Args:\n",
    "            vectorizer_filepath (str): the location to save the vectorizer\n",
    "        \"\"\"\n",
    "        with open(vectorizer_filepath, \"w\") as fp:\n",
    "            json.dump(self._vectorizer.to_serializable(), fp)\n",
    "\n",
    "    def get_vectorizer(self):\n",
    "        \"\"\" returns the vectorizer \"\"\"\n",
    "        return self._vectorizer\n",
    "\n",
    "    def set_split(self, split=\"train\"):\n",
    "        self._target_split = split\n",
    "        self._target_df, self._target_size = self._lookup_dict[split]\n",
    "\n",
    "    def __len__(self):\n",
    "        return self._target_size\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        \"\"\"the primary entry point method for PyTorch datasets\n",
    "        \n",
    "        Args:\n",
    "            index (int): the index to the data point \n",
    "        Returns:\n",
    "            a dictionary holding the data point's:\n",
    "                features (x_data)\n",
    "                label (y_target)\n",
    "                feature length (x_length)\n",
    "        \"\"\"\n",
    "        row = self._target_df.iloc[index]\n",
    "        \n",
    "        review_vector, vec_length = \\\n",
    "            self._vectorizer.vectorize(row.review, self._max_seq_length)\n",
    "        \n",
    "        rating_index = \\\n",
    "            self._vectorizer.rating_vocab.lookup_token(row.rating)\n",
    "\n",
    "        return {'x_data': review_vector, \n",
    "                'y_target': rating_index, \n",
    "                'x_length': vec_length}\n",
    "\n",
    "    def get_num_batches(self, batch_size):\n",
    "        \"\"\"Given a batch size, return the number of batches in the dataset\n",
    "        \n",
    "        Args:\n",
    "            batch_size (int)\n",
    "        Returns:\n",
    "            number of batches in the dataset\n",
    "        \"\"\"\n",
    "        return len(self) // batch_size\n",
    "\n",
    "def generate_batches(dataset, batch_size, shuffle=True,\n",
    "                     drop_last=False, device=\"cpu\"): \n",
    "    \"\"\"\n",
    "    A generator function which wraps the PyTorch DataLoader. It will \n",
    "      ensure each tensor is on the write device location.\n",
    "    \"\"\"\n",
    "    dataloader = DataLoader(dataset=dataset, batch_size=batch_size,\n",
    "                            shuffle=shuffle, drop_last=drop_last)\n",
    "\n",
    "    for data_dict in dataloader:\n",
    "        out_data_dict = {}\n",
    "        for name, tensor in data_dict.items():\n",
    "            out_data_dict[name] = data_dict[name].to(device)\n",
    "        yield out_data_dict\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def column_gather(y_out, x_lengths):\n",
    "    '''Get a specific vector from each batch datapoint in `y_out`.\n",
    "\n",
    "    More precisely, iterate over batch row indices, get the vector that's at\n",
    "    the position indicated by the corresponding value in `x_lengths` at the row\n",
    "    index.\n",
    "\n",
    "    Args:\n",
    "        y_out (torch.FloatTensor, torch.cuda.FloatTensor)\n",
    "            shape: (batch, sequence, feature)\n",
    "        x_lengths (torch.LongTensor, torch.cuda.LongTensor)\n",
    "            shape: (batch,)\n",
    "\n",
    "    Returns:\n",
    "        y_out (torch.FloatTensor, torch.cuda.FloatTensor)\n",
    "            shape: (batch, feature)\n",
    "    '''\n",
    "    x_lengths = x_lengths.long().detach().cpu().numpy() - 1\n",
    "\n",
    "    out = []\n",
    "    for batch_index, column_index in enumerate(x_lengths):\n",
    "        out.append(y_out[batch_index, column_index])\n",
    "\n",
    "    return torch.stack(out)\n",
    "\n",
    "def column_summation(y_out, x_lengths):\n",
    "    '''Get a max or mean vector from each batch datapoint in `y_out`.\n",
    "\n",
    "    More precisely, iterate over batch row indices, get the max or mean vector of all the vectors by \n",
    "    the position indicated by the corresponding value in `x_lengths` at the row index.\n",
    "\n",
    "    Args:\n",
    "        y_out (torch.FloatTensor, torch.cuda.FloatTensor)\n",
    "            shape: (batch, sequence, feature)\n",
    "        x_lengths (torch.LongTensor, torch.cuda.LongTensor)\n",
    "            shape: (batch,)\n",
    "\n",
    "    Returns:\n",
    "        y_out (torch.FloatTensor, torch.cuda.FloatTensor)\n",
    "            shape: (batch, feature)\n",
    "    '''\n",
    "    x_lengths = x_lengths.long().detach().cpu().numpy() - 1\n",
    "\n",
    "    out = []\n",
    "    for batch_index, column_index in enumerate(x_lengths):      \n",
    "        #out.append(y_out[batch_index, 0:column_index].mean(dim=0))  # get the mean vector\n",
    "        out.append(y_out[batch_index, 0:column_index].max(dim=0).values)  # get the max vector\n",
    "\n",
    "    return torch.stack(out)\n",
    "\n",
    "\n",
    "class ElmanRNN(nn.Module):\n",
    "    \"\"\" an Elman RNN built using the RNNCell \"\"\"\n",
    "    def __init__(self, input_size, hidden_size, batch_first=False):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            input_size (int): size of the input vectors\n",
    "            hidden_size (int): size of the hidden state vectors\n",
    "            bathc_first (bool): whether the 0th dimension is batch\n",
    "        \"\"\"\n",
    "        super(ElmanRNN, self).__init__()\n",
    "        \n",
    "        self.rnn_cell = nn.RNNCell(input_size, hidden_size)\n",
    "        \n",
    "        self.batch_first = batch_first\n",
    "        self.hidden_size = hidden_size\n",
    "\n",
    "    def _initial_hidden(self, batch_size):\n",
    "        return torch.zeros((batch_size, self.hidden_size))\n",
    "\n",
    "    def forward(self, x_in, initial_hidden=None):\n",
    "        \"\"\"The forward pass of the ElmanRNN\n",
    "        \n",
    "        Args:\n",
    "            x_in (torch.Tensor): an input data tensor. \n",
    "                If self.batch_first: x_in.shape = (batch, seq_size, feat_size)\n",
    "                Else: x_in.shape = (seq_size, batch, feat_size)\n",
    "            initial_hidden (torch.Tensor): the initial hidden state for the RNN\n",
    "        Returns:\n",
    "            hiddens (torch.Tensor): The outputs of the RNN at each time step. \n",
    "                If self.batch_first: hiddens.shape = (batch, seq_size, hidden_size)\n",
    "                Else: hiddens.shape = (seq_size, batch, hidden_size)\n",
    "        \"\"\"\n",
    "        if self.batch_first:\n",
    "            batch_size, seq_size, feat_size = x_in.size()\n",
    "            x_in = x_in.permute(1, 0, 2)\n",
    "        else:\n",
    "            seq_size, batch_size, feat_size = x_in.size()\n",
    "    \n",
    "        hiddens = []\n",
    "\n",
    "        if initial_hidden is None:\n",
    "            initial_hidden = self._initial_hidden(batch_size)\n",
    "            initial_hidden = initial_hidden.to(x_in.device)\n",
    "\n",
    "        hidden_t = initial_hidden\n",
    "                    \n",
    "        for t in range(seq_size):\n",
    "            hidden_t = self.rnn_cell(x_in[t], hidden_t)  # x_in[t]: (batch, feat_size); hidden_t: (batch, hidden_size)\n",
    "            hiddens.append(hidden_t)\n",
    "            \n",
    "        hiddens = torch.stack(hiddens)\n",
    "\n",
    "        if self.batch_first:\n",
    "            hiddens = hiddens.permute(1, 0, 2)\n",
    "\n",
    "        return hiddens\n",
    "\n",
    "\n",
    "\n",
    "class ReviewClassifier(nn.Module):\n",
    "    \"\"\" A Classifier with an RNN to extract features and an MLP to classify \"\"\"\n",
    "    def __init__(self, embedding_size, num_embeddings, num_classes,\n",
    "                 rnn_hidden_size, bidirectional=False, batch_first=True, padding_idx=0):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            embedding_size (int): The size of the word embeddings\n",
    "            num_embeddings (int): The number of words to embed\n",
    "            num_classes (int): The size of the prediction vector \n",
    "                Note: the number of sentiment polarities\n",
    "            bidirectional (bool): Informs whether bidrectional RNN is used\n",
    "            rnn_hidden_size (int): The size of the RNN's hidden state\n",
    "            batch_first (bool): Informs whether the input tensors will \n",
    "                have batch or the sequence on the 0th dimension\n",
    "            padding_idx (int): The index for the tensor padding; \n",
    "                see torch.nn.Embedding\n",
    "        \"\"\"\n",
    "        super(ReviewClassifier, self).__init__()\n",
    "\n",
    "        if bidirectional == False:\n",
    "             self.num_directions = 1\n",
    "        else:\n",
    "             self.num_directions = 2\n",
    "        \n",
    "        self.emb = nn.Embedding(num_embeddings=num_embeddings,\n",
    "                                embedding_dim=embedding_size,\n",
    "                                padding_idx=padding_idx)\n",
    "        #self.rnn = ElmanRNN(input_size=embedding_size,\n",
    "        #                     hidden_size=rnn_hidden_size,\n",
    "        #                     batch_first=batch_first)\n",
    "\n",
    "        #self.rnn = nn.RNN(input_size=embedding_size,\n",
    "        self.rnn = nn.GRU(input_size=embedding_size,\n",
    "        #self.rnn = nn.LSTM(input_size=embedding_size,\n",
    "                             hidden_size=rnn_hidden_size,\n",
    "                             batch_first=batch_first, \n",
    "                             num_layers = 1,\n",
    "                             dropout = 0.0, \n",
    "                             bidirectional=bidirectional)\n",
    "        \n",
    "        #self.fc1 = nn.Linear(in_features=rnn_hidden_size*self.num_directions,\n",
    "        #                 out_features=rnn_hidden_size*self.num_directions)\n",
    "        self.fc2 = nn.Linear(in_features=rnn_hidden_size*self.num_directions,\n",
    "                          out_features=num_classes)\n",
    "        # for batch norm\n",
    "        self.bn1 = nn.BatchNorm1d(rnn_hidden_size*self.num_directions) \n",
    "\n",
    "\n",
    "    def forward(self, x_in, x_lengths=None, apply_softmax=False):\n",
    "        \"\"\"The forward pass of the classifier\n",
    "        \n",
    "        Args:\n",
    "            x_in (torch.Tensor): an input data tensor. \n",
    "                x_in.shape should be (batch, input_dim)\n",
    "            x_lengths (torch.Tensor): the lengths of each sequence in the batch.\n",
    "                They are used to find the final vector of each sequence\n",
    "            apply_softmax (bool): a flag for the softmax activation\n",
    "                should be false if used with the Cross Entropy losses\n",
    "        Returns:\n",
    "            the resulting tensor. tensor.shape should be (batch, output_dim)\n",
    "        \"\"\"\n",
    "        x_embedded = self.emb(x_in) # x_embedded: (batch, seq_size, feat_size)\n",
    "               \n",
    "        # create PackedSequence; x_packed.data.shape=(number_items, embeddign_size)\n",
    "        #x_packed = pack_padded_sequence(x_embedded, x_lengths.detach().cpu().numpy(), batch_first=True)\n",
    "        y_out, _ = self.rnn(x_embedded)        \n",
    "        #y_out, _ = pad_packed_sequence(y_out, batch_first=True) # y_out: (batch, seq_size, hidden_size*num_directions)\n",
    "        \n",
    "        if x_lengths is not None:\n",
    "             #y_out = column_gather(y_out, x_lengths)   # y_out gets the last hidden vector of each input: (batch, hidden_size*num_directions)\n",
    "             y_out = column_summation(y_out, x_lengths) # y_out gets the max or mean hidden vector of each input\n",
    "        else:\n",
    "             y_out = y_out[:, -1, :]\n",
    "\n",
    "        \n",
    "        # with batch norm and dropout\n",
    "        #y_out = F.relu(self.bn1(self.fc1(F.dropout(y_out, 0.5, training=self.training))))\n",
    "        #y_out = F.relu(self.bn1(self.fc1(y_out)))\n",
    "\n",
    "        \n",
    "        # with dropout\n",
    "        #y_out = self.fc2(F.dropout(y_out, 0.4, training=self.training))          # y_out: (batch, num_classes)\n",
    "        y_out = self.fc2(y_out)\n",
    "\n",
    "        if apply_softmax:\n",
    "            y_out = F.softmax(y_out, dim=1)\n",
    "\n",
    "        return y_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_seed_everywhere(seed, cuda):\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    if cuda:\n",
    "        torch.cuda.manual_seed_all(seed)\n",
    "\n",
    "def handle_dirs(dirpath):\n",
    "    if not os.path.exists(dirpath):\n",
    "        os.makedirs(dirpath)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "code_folding": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using CUDA: False\n"
     ]
    }
   ],
   "source": [
    "args = Namespace(\n",
    "    # Data and path information\n",
    "    review_csv=\"data/rt-polaritydata/reviews_with_splits_lite.csv\",\n",
    "    vectorizer_file=\"vectorizer.json\",\n",
    "    model_state_file=\"model.pth\",\n",
    "    save_dir=\"model_storage/rt-polaritydata/review_classification\",\n",
    "    # Model hyper parameter\n",
    "    word_embedding_size=200,\n",
    "    rnn_hidden_size=200,\n",
    "    bidirectional=False,\n",
    "    #bidirectional=True,\n",
    "    # Training hyper parameter\n",
    "    num_epochs=100,\n",
    "    #num_epochs=200,\n",
    "    learning_rate=1e-3,\n",
    "    batch_size=64,\n",
    "    seed=1337,\n",
    "    early_stopping_criteria=5,\n",
    "    # Runtime hyper parameter\n",
    "    cuda=True,\n",
    "    catch_keyboard_interrupt=True,\n",
    "    reload_from_files=False,\n",
    "    expand_filepaths_to_save_dir=True,\n",
    ")\n",
    "\n",
    "# Check CUDA\n",
    "if not torch.cuda.is_available():\n",
    "    args.cuda = False\n",
    "\n",
    "args.device = torch.device(\"cuda\" if args.cuda else \"cpu\")\n",
    "    \n",
    "print(\"Using CUDA: {}\".format(args.cuda))\n",
    "\n",
    "\n",
    "if args.expand_filepaths_to_save_dir:\n",
    "    args.vectorizer_file = os.path.join(args.save_dir,\n",
    "                                        args.vectorizer_file)\n",
    "\n",
    "    args.model_state_file = os.path.join(args.save_dir,\n",
    "                                         args.model_state_file)\n",
    "    \n",
    "# Set seed for reproducibility\n",
    "set_seed_everywhere(args.seed, args.cuda)\n",
    "\n",
    "# handle dirs\n",
    "handle_dirs(args.save_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "code_folding": [
     0,
     4
    ]
   },
   "outputs": [],
   "source": [
    "if args.reload_from_files and os.path.exists(args.vectorizer_file):\n",
    "    # training from a checkpoint\n",
    "    dataset = ReviewDataset.load_dataset_and_load_vectorizer(args.review_csv, \n",
    "                                                              args.vectorizer_file)\n",
    "else:\n",
    "    # create dataset and vectorizer\n",
    "    dataset = ReviewDataset.load_dataset_and_make_vectorizer(args.review_csv)\n",
    "    dataset.save_vectorizer(args.vectorizer_file)\n",
    "\n",
    "vectorizer = dataset.get_vectorizer()\n",
    "\n",
    "classifier = ReviewClassifier(embedding_size=args.word_embedding_size, \n",
    "                               num_embeddings=len(vectorizer.review_vocab),\n",
    "                               num_classes=len(vectorizer.rating_vocab),\n",
    "                               rnn_hidden_size=args.rnn_hidden_size,\n",
    "                               padding_idx=vectorizer.review_vocab.mask_index,\n",
    "                               bidirectional=args.bidirectional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5571"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(vectorizer.review_vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'<MASK>': 0,\n",
       " '<UNK>': 1,\n",
       " '<BEGIN>': 2,\n",
       " '<END>': 3,\n",
       " 'this': 4,\n",
       " 'plot': 5,\n",
       " 'feels': 6,\n",
       " 'especially': 7,\n",
       " 'thin': 8,\n",
       " 'stretched': 9,\n",
       " 'over': 10,\n",
       " 'the': 11,\n",
       " 'nearly': 12,\n",
       " 'minute': 13,\n",
       " 'running': 14,\n",
       " 'time': 15,\n",
       " 'complete': 16,\n",
       " 'lack': 17,\n",
       " 'of': 18,\n",
       " 'originality': 19,\n",
       " 'cleverness': 20,\n",
       " 'or': 21,\n",
       " 'even': 22,\n",
       " 'effort': 23,\n",
       " 'there': 24,\n",
       " 's': 25,\n",
       " 'an': 26,\n",
       " 'admirable': 27,\n",
       " 'rigor': 28,\n",
       " 'to': 29,\n",
       " 'relentless': 30,\n",
       " 'anger': 31,\n",
       " 'and': 32,\n",
       " 'script': 33,\n",
       " 'refusal': 34,\n",
       " 'a': 35,\n",
       " 'happy': 36,\n",
       " 'ending': 37,\n",
       " 'but': 38,\n",
       " 'as': 39,\n",
       " 'those': 40,\n",
       " 'on': 41,\n",
       " 'you': 42,\n",
       " 'realize': 43,\n",
       " 'no': 44,\n",
       " 'place': 45,\n",
       " 'for': 46,\n",
       " 'story': 47,\n",
       " 'go': 48,\n",
       " 'down': 49,\n",
       " 'is': 50,\n",
       " 'group': 51,\n",
       " 'more': 52,\n",
       " 'self': 53,\n",
       " 'absorbed': 54,\n",
       " 'women': 55,\n",
       " 'than': 56,\n",
       " 'mother': 57,\n",
       " 'in': 58,\n",
       " 'film': 59,\n",
       " 'i': 60,\n",
       " 'don': 61,\n",
       " 't': 62,\n",
       " 'think': 63,\n",
       " 'so': 64,\n",
       " 'nothing': 65,\n",
       " 'wrong': 66,\n",
       " 'with': 67,\n",
       " 'performances': 68,\n",
       " 'here': 69,\n",
       " 'characters': 70,\n",
       " 'me': 71,\n",
       " 'not': 72,\n",
       " 'really': 73,\n",
       " 'bad': 74,\n",
       " 'much': 75,\n",
       " 'distasteful': 76,\n",
       " 'we': 77,\n",
       " 'need': 78,\n",
       " 'suspense': 79,\n",
       " 'dramas': 80,\n",
       " 'right': 81,\n",
       " 'now': 82,\n",
       " 'like': 83,\n",
       " 'thrillers': 84,\n",
       " 'low': 85,\n",
       " 'budget': 86,\n",
       " 'full': 87,\n",
       " 'frontal': 88,\n",
       " 'was': 89,\n",
       " 'one': 90,\n",
       " 'year': 91,\n",
       " 'intentionally': 92,\n",
       " 'obscure': 93,\n",
       " 'indulgent': 94,\n",
       " 'pictures': 95,\n",
       " 'solaris': 96,\n",
       " 'its': 97,\n",
       " 'big': 98,\n",
       " 'brother': 99,\n",
       " 'proof': 100,\n",
       " 'that': 101,\n",
       " 'thriller': 102,\n",
       " 'can': 103,\n",
       " 'be': 104,\n",
       " 'shot': 105,\n",
       " 'expertly': 106,\n",
       " 'cast': 107,\n",
       " 'paced': 108,\n",
       " 'crisp': 109,\n",
       " 'professionalism': 110,\n",
       " 'still': 111,\n",
       " 'if': 112,\n",
       " 'twists': 113,\n",
       " 'turns': 114,\n",
       " 'hold': 115,\n",
       " 'surprise': 116,\n",
       " 'yesterday': 117,\n",
       " 'report': 118,\n",
       " 'pitch': 119,\n",
       " 'your': 120,\n",
       " 'expectations': 121,\n",
       " 'at': 122,\n",
       " 'all': 123,\n",
       " 'could': 124,\n",
       " 'do': 125,\n",
       " 'worse': 126,\n",
       " 'oddly': 127,\n",
       " 'cheerful': 128,\n",
       " 'particularly': 129,\n",
       " 'funny': 130,\n",
       " 'body': 131,\n",
       " 'farce': 132,\n",
       " 'unless': 133,\n",
       " 'bob': 134,\n",
       " 'crane': 135,\n",
       " 'someone': 136,\n",
       " 'particular': 137,\n",
       " 'interest': 138,\n",
       " 'impressive': 139,\n",
       " 'direction': 140,\n",
       " 'aren': 141,\n",
       " 'likely': 142,\n",
       " 'leave': 143,\n",
       " 'lasting': 144,\n",
       " 'impression': 145,\n",
       " 'loud': 146,\n",
       " 'bang': 147,\n",
       " 'drum': 148,\n",
       " 'bore': 149,\n",
       " 'contains': 150,\n",
       " 'good': 151,\n",
       " 'jokes': 152,\n",
       " 'scenes': 153,\n",
       " 'barely': 154,\n",
       " 'moment': 155,\n",
       " 'when': 156,\n",
       " 'carvey': 157,\n",
       " 'saturday': 158,\n",
       " 'night': 159,\n",
       " 'live': 160,\n",
       " 'rises': 161,\n",
       " 'above': 162,\n",
       " 'level': 163,\n",
       " 'embarrassment': 164,\n",
       " 'gets': 165,\n",
       " 'most': 166,\n",
       " 'minutes': 167,\n",
       " 'screen': 168,\n",
       " 'viewers': 169,\n",
       " 'will': 170,\n",
       " 'wish': 171,\n",
       " 'had': 172,\n",
       " 'been': 173,\n",
       " 'queen': 174,\n",
       " 'less': 175,\n",
       " 'damned': 176,\n",
       " 'horror': 177,\n",
       " 'movie': 178,\n",
       " 'seriously': 179,\n",
       " 'dumb': 180,\n",
       " 'which': 181,\n",
       " 'somewhat': 182,\n",
       " 'pleasure': 183,\n",
       " 'watching': 184,\n",
       " 'them': 185,\n",
       " 'by': 186,\n",
       " 'creepy': 187,\n",
       " 'bug': 188,\n",
       " 'things': 189,\n",
       " 'only': 190,\n",
       " 'darkness': 191,\n",
       " 'though': 192,\n",
       " 'harris': 193,\n",
       " 'affecting': 194,\n",
       " 'times': 195,\n",
       " 'he': 196,\n",
       " 'cannot': 197,\n",
       " 'overcome': 198,\n",
       " 'sense': 199,\n",
       " 'pumpkin': 200,\n",
       " 'mere': 201,\n",
       " 'two': 202,\n",
       " 'directors': 203,\n",
       " 'far': 204,\n",
       " 'endearing': 205,\n",
       " 'does': 206,\n",
       " 'little': 207,\n",
       " 'play': 208,\n",
       " 'innocuous': 209,\n",
       " 'game': 210,\n",
       " 'fill': 211,\n",
       " 'tragic': 212,\n",
       " 'past': 213,\n",
       " 'mixture': 214,\n",
       " 'cutesy': 215,\n",
       " 'romance': 216,\n",
       " 'dark': 217,\n",
       " 'satire': 218,\n",
       " 'murder': 219,\n",
       " 'mystery': 220,\n",
       " 'baffling': 221,\n",
       " 'mixed': 222,\n",
       " 'platter': 223,\n",
       " 'gritty': 224,\n",
       " 'realism': 225,\n",
       " 'magic': 226,\n",
       " 'hard': 227,\n",
       " 'swallow': 228,\n",
       " 'premise': 229,\n",
       " 'episode': 230,\n",
       " 'tv': 231,\n",
       " 'series': 232,\n",
       " 'pitfalls': 233,\n",
       " 'such': 234,\n",
       " 'd': 235,\n",
       " 'expect': 236,\n",
       " 'list': 237,\n",
       " 'grey': 238,\n",
       " 'zone': 239,\n",
       " 'attempts': 240,\n",
       " 'ends': 241,\n",
       " 'up': 242,\n",
       " 'merely': 243,\n",
       " 'pretentious': 244,\n",
       " 'grisly': 245,\n",
       " 'sort': 246,\n",
       " 'way': 247,\n",
       " 'how': 248,\n",
       " 'about': 249,\n",
       " 'starting': 250,\n",
       " 'original': 251,\n",
       " 'instead': 252,\n",
       " 'just': 253,\n",
       " 'extreme': 254,\n",
       " 'humor': 255,\n",
       " 'gross': 256,\n",
       " 'out': 257,\n",
       " 'gags': 258,\n",
       " 'top': 259,\n",
       " 'same': 260,\n",
       " 'old': 261,\n",
       " 'crap': 262,\n",
       " 'too': 263,\n",
       " 'gory': 264,\n",
       " 'comedy': 265,\n",
       " 'silly': 266,\n",
       " 'effective': 267,\n",
       " 'diane': 268,\n",
       " 'lane': 269,\n",
       " 'sophisticated': 270,\n",
       " 'performance': 271,\n",
       " 'rescue': 272,\n",
       " 'lyne': 273,\n",
       " 'unfaithful': 274,\n",
       " 'from': 275,\n",
       " 'word': 276,\n",
       " 'fisted': 277,\n",
       " 'who': 278,\n",
       " 'manages': 279,\n",
       " 'blast': 280,\n",
       " 'his': 281,\n",
       " 'approach': 282,\n",
       " 'it': 283,\n",
       " 'uses': 284,\n",
       " 'pain': 285,\n",
       " 'violence': 286,\n",
       " 'war': 287,\n",
       " 'background': 288,\n",
       " 'material': 289,\n",
       " 'color': 290,\n",
       " 'day': 291,\n",
       " 'taste': 292,\n",
       " 'fizz': 293,\n",
       " 'her': 294,\n",
       " 'fans': 295,\n",
       " 'walked': 296,\n",
       " 'words': 297,\n",
       " 'horrible': 298,\n",
       " 'terrible': 299,\n",
       " 'fun': 300,\n",
       " 'they': 301,\n",
       " 'didn': 302,\n",
       " 'mind': 303,\n",
       " 'ticket': 304,\n",
       " 'cost': 305,\n",
       " 'case': 306,\n",
       " 'kind': 307,\n",
       " 'leaves': 308,\n",
       " 'vague': 309,\n",
       " 'impressions': 310,\n",
       " 'nasty': 311,\n",
       " 'clear': 312,\n",
       " 'memory': 313,\n",
       " 'mechanics': 314,\n",
       " 'worth': 315,\n",
       " 'price': 316,\n",
       " 'match': 317,\n",
       " 'should': 318,\n",
       " 'used': 319,\n",
       " 'burn': 320,\n",
       " 'every': 321,\n",
       " 'director': 322,\n",
       " 'george': 323,\n",
       " 'hickenlooper': 324,\n",
       " 'has': 325,\n",
       " 'some': 326,\n",
       " 'success': 327,\n",
       " 'documentaries': 328,\n",
       " 'juvenile': 329,\n",
       " 'camera': 330,\n",
       " 'movements': 331,\n",
       " 'school': 332,\n",
       " 'maudlin': 333,\n",
       " 'might': 334,\n",
       " 'have': 335,\n",
       " 'him': 336,\n",
       " 'into': 337,\n",
       " 'first': 338,\n",
       " 'certain': 339,\n",
       " 'base': 340,\n",
       " 'blue': 341,\n",
       " 'crush': 342,\n",
       " 'delivers': 343,\n",
       " 'what': 344,\n",
       " 'promises': 345,\n",
       " 'well': 346,\n",
       " 'enough': 347,\n",
       " 'recommend': 348,\n",
       " 'exhausting': 349,\n",
       " 'family': 350,\n",
       " 'drama': 351,\n",
       " 'empire': 352,\n",
       " 'flick': 353,\n",
       " 'subject': 354,\n",
       " 'matter': 355,\n",
       " 'hero': 356,\n",
       " 'innocence': 357,\n",
       " 'soon': 358,\n",
       " 'becomes': 359,\n",
       " 'new': 360,\n",
       " 'guy': 361,\n",
       " 'bull': 362,\n",
       " 'recycled': 363,\n",
       " 'encouraging': 364,\n",
       " 'enormous': 365,\n",
       " 'comic': 366,\n",
       " 'potential': 367,\n",
       " 'idiot': 368,\n",
       " 'remains': 369,\n",
       " 'sadly': 370,\n",
       " 'feardotcom': 371,\n",
       " 'interesting': 372,\n",
       " 'meditation': 373,\n",
       " 'nature': 374,\n",
       " 'otherworldly': 375,\n",
       " 'channel': 376,\n",
       " 'simply': 377,\n",
       " 'routine': 378,\n",
       " 'while': 379,\n",
       " 'better': 380,\n",
       " 'focused': 381,\n",
       " 'incomprehensible': 382,\n",
       " 'anne': 383,\n",
       " 'rice': 384,\n",
       " 'novel': 385,\n",
       " 'based': 386,\n",
       " 'upon': 387,\n",
       " 'pointless': 388,\n",
       " 'meandering': 389,\n",
       " 'celebration': 390,\n",
       " 'vampire': 391,\n",
       " 'tortured': 392,\n",
       " 'lifestyle': 393,\n",
       " 'latest': 394,\n",
       " 'erotic': 395,\n",
       " 'further': 396,\n",
       " 'demonstrates': 397,\n",
       " 'storytelling': 398,\n",
       " 'skills': 399,\n",
       " 'soderbergh': 400,\n",
       " 'seems': 401,\n",
       " 'capable': 402,\n",
       " 'delivering': 403,\n",
       " 'artfully': 404,\n",
       " 'earnest': 405,\n",
       " 'genuine': 406,\n",
       " 'depth': 407,\n",
       " 'would': 408,\n",
       " 'make': 409,\n",
       " 'once': 410,\n",
       " 'rush': 411,\n",
       " 'save': 412,\n",
       " 'did': 413,\n",
       " 'become': 414,\n",
       " 'very': 415,\n",
       " 'involved': 416,\n",
       " 'proceedings': 417,\n",
       " 'starts': 418,\n",
       " 'dreary': 419,\n",
       " 'humorless': 420,\n",
       " 'soap': 421,\n",
       " 'opera': 422,\n",
       " 'casual': 423,\n",
       " 'moviegoers': 424,\n",
       " 'stumble': 425,\n",
       " 'rules': 426,\n",
       " 'expecting': 427,\n",
       " 'slice': 428,\n",
       " 'american': 429,\n",
       " 'pie': 430,\n",
       " 'starring': 431,\n",
       " 'kid': 432,\n",
       " 'dawson': 433,\n",
       " 'll': 434,\n",
       " 'probably': 435,\n",
       " 'run': 436,\n",
       " 'screaming': 437,\n",
       " 'spends': 438,\n",
       " 'schneider': 439,\n",
       " 'newcomer': 440,\n",
       " 'funnier': 441,\n",
       " 'something': 442,\n",
       " 'are': 443,\n",
       " 'care': 444,\n",
       " 'sophomoric': 445,\n",
       " 'exploration': 446,\n",
       " 'life': 447,\n",
       " 'problems': 448,\n",
       " 'people': 449,\n",
       " 'long': 450,\n",
       " 'ago': 451,\n",
       " 'least': 452,\n",
       " 'got': 453,\n",
       " 'tired': 454,\n",
       " 'bond': 455,\n",
       " 'goes': 456,\n",
       " 'off': 457,\n",
       " 'path': 458,\n",
       " 'necessarily': 459,\n",
       " 'inoffensive': 460,\n",
       " 'built': 461,\n",
       " 'inspire': 462,\n",
       " 'young': 463,\n",
       " 'set': 464,\n",
       " 'soundtrack': 465,\n",
       " 'beach': 466,\n",
       " 'party': 467,\n",
       " 'pop': 468,\n",
       " 'numbers': 469,\n",
       " 'aside': 470,\n",
       " 'remarkable': 471,\n",
       " 'awesome': 472,\n",
       " 'scenery': 473,\n",
       " 'exciting': 474,\n",
       " 'disappointing': 475,\n",
       " 'saga': 476,\n",
       " 'murphy': 477,\n",
       " 'wilson': 478,\n",
       " 'actually': 479,\n",
       " 'pretty': 480,\n",
       " 'team': 481,\n",
       " 'project': 482,\n",
       " 'surrounding': 483,\n",
       " 'rote': 484,\n",
       " 'end': 485,\n",
       " 'getting': 486,\n",
       " 'surfing': 487,\n",
       " 'movies': 488,\n",
       " 'memorable': 489,\n",
       " 'stunts': 490,\n",
       " 'lots': 491,\n",
       " 'between': 492,\n",
       " 'telegraphed': 493,\n",
       " 'advance': 494,\n",
       " 'must': 495,\n",
       " 'lost': 496,\n",
       " 'takes': 497,\n",
       " 'strange': 498,\n",
       " 'waste': 499,\n",
       " 'talents': 500,\n",
       " 'robert': 501,\n",
       " 'love': 502,\n",
       " 'liza': 503,\n",
       " 'festival': 504,\n",
       " 'circuit': 505,\n",
       " 'slight': 506,\n",
       " 'done': 507,\n",
       " 'thousand': 508,\n",
       " 'already': 509,\n",
       " 'soul': 510,\n",
       " 'lacking': 511,\n",
       " 'character': 512,\n",
       " 'itself': 513,\n",
       " 'sweet': 514,\n",
       " 'bit': 515,\n",
       " 'precious': 516,\n",
       " 'start': 517,\n",
       " 'familiar': 518,\n",
       " 'children': 519,\n",
       " 'packed': 520,\n",
       " 'adventure': 521,\n",
       " 'worthwhile': 522,\n",
       " 'environmental': 523,\n",
       " 'message': 524,\n",
       " 'great': 525,\n",
       " 'kids': 526,\n",
       " 'parents': 527,\n",
       " 'other': 528,\n",
       " 'hand': 529,\n",
       " 'ahead': 530,\n",
       " 'isn': 531,\n",
       " 'clever': 532,\n",
       " 'innuendo': 533,\n",
       " 'thought': 534,\n",
       " 'my': 535,\n",
       " 'own': 536,\n",
       " 'watch': 537,\n",
       " 'stopped': 538,\n",
       " 'keeping': 539,\n",
       " 'through': 540,\n",
       " 'clockstoppers': 541,\n",
       " 'ensemble': 542,\n",
       " 'player': 543,\n",
       " 'notice': 544,\n",
       " 'ritchie': 545,\n",
       " 'stock': 546,\n",
       " 'barrels': 547,\n",
       " 'unlikely': 548,\n",
       " 'name': 549,\n",
       " 'basis': 550,\n",
       " 'vehicle': 551,\n",
       " 'pilot': 552,\n",
       " 'teen': 553,\n",
       " 'targeted': 554,\n",
       " 'action': 555,\n",
       " 'confusing': 556,\n",
       " 'tones': 557,\n",
       " 'styles': 558,\n",
       " 'romantic': 559,\n",
       " 'trifle': 560,\n",
       " 'next': 561,\n",
       " 'turgid': 562,\n",
       " 'vision': 563,\n",
       " 'mature': 564,\n",
       " 'call': 565,\n",
       " 'pity': 566,\n",
       " 'sympathy': 567,\n",
       " 'anachronistic': 568,\n",
       " 'haunting': 569,\n",
       " 'imagined': 570,\n",
       " 'glory': 571,\n",
       " 'their': 572,\n",
       " 'each': 573,\n",
       " 'potentially': 574,\n",
       " 'idea': 575,\n",
       " 'ruined': 576,\n",
       " 'amateurish': 577,\n",
       " 'writing': 578,\n",
       " 'acting': 579,\n",
       " 'third': 580,\n",
       " 'limited': 581,\n",
       " 'short': 582,\n",
       " 'gone': 583,\n",
       " 'lot': 584,\n",
       " 'ultimately': 585,\n",
       " 'endeavor': 586,\n",
       " 'put': 587,\n",
       " 'find': 588,\n",
       " 'leon': 589,\n",
       " 'explosion': 590,\n",
       " 'ballistic': 591,\n",
       " 'ecks': 592,\n",
       " 'vs': 593,\n",
       " 'sever': 594,\n",
       " 'doesn': 595,\n",
       " 'show': 596,\n",
       " 'creative': 597,\n",
       " 'process': 598,\n",
       " 'created': 599,\n",
       " 'non': 600,\n",
       " 'fan': 601,\n",
       " 'figure': 602,\n",
       " 'makes': 603,\n",
       " 'wilco': 604,\n",
       " 'deal': 605,\n",
       " 'paint': 606,\n",
       " 'images': 607,\n",
       " 'makhmalbaf': 608,\n",
       " 'keeps': 609,\n",
       " 'distance': 610,\n",
       " 'difficult': 611,\n",
       " 'feel': 612,\n",
       " 'anything': 613,\n",
       " 'beyond': 614,\n",
       " 'mild': 615,\n",
       " 'detached': 616,\n",
       " 'blade': 617,\n",
       " 'ii': 618,\n",
       " 'heavy': 619,\n",
       " 'guns': 620,\n",
       " 'filmed': 621,\n",
       " 'martial': 622,\n",
       " 'arts': 623,\n",
       " 'computer': 624,\n",
       " 'effects': 625,\n",
       " 'moves': 626,\n",
       " 'serve': 627,\n",
       " 'purpose': 628,\n",
       " 'attention': 629,\n",
       " 'themselves': 630,\n",
       " 'godard': 631,\n",
       " 'ode': 632,\n",
       " 'tackling': 633,\n",
       " 'rambling': 634,\n",
       " 'incoherent': 635,\n",
       " 'topical': 636,\n",
       " 'excess': 637,\n",
       " 'praise': 638,\n",
       " 'ponderous': 639,\n",
       " 'unfocused': 640,\n",
       " 're': 641,\n",
       " 'conscious': 642,\n",
       " 'spontaneous': 643,\n",
       " 'remake': 644,\n",
       " 'm': 645,\n",
       " 'sure': 646,\n",
       " 'filmmakers': 647,\n",
       " 'found': 648,\n",
       " 'concept': 649,\n",
       " 'anybody': 650,\n",
       " 'ever': 651,\n",
       " 'seen': 652,\n",
       " 'independent': 653,\n",
       " 'cheap': 654,\n",
       " 'clich': 655,\n",
       " 'deeply': 656,\n",
       " 'serious': 657,\n",
       " 'cares': 658,\n",
       " 'often': 659,\n",
       " 'history': 660,\n",
       " 'intricate': 661,\n",
       " 'connections': 662,\n",
       " 'multiple': 663,\n",
       " 'cinematic': 664,\n",
       " 'disaster': 665,\n",
       " 'admission': 666,\n",
       " 'factor': 667,\n",
       " 'alone': 668,\n",
       " 'gimmicky': 669,\n",
       " 'compelling': 670,\n",
       " 'interview': 671,\n",
       " 'loses': 672,\n",
       " 'overall': 673,\n",
       " 'rather': 674,\n",
       " 'documentary': 675,\n",
       " 'buy': 676,\n",
       " 'adventures': 677,\n",
       " 'nash': 678,\n",
       " 'whole': 679,\n",
       " 'palpable': 680,\n",
       " 'hinges': 681,\n",
       " 'strains': 682,\n",
       " 'viewer': 683,\n",
       " 'haunted': 684,\n",
       " 'plays': 685,\n",
       " 'nice': 686,\n",
       " 'n': 687,\n",
       " 'safe': 688,\n",
       " 'week': 689,\n",
       " 'blown': 690,\n",
       " 'jones': 691,\n",
       " 'helps': 692,\n",
       " 'breathe': 693,\n",
       " 'predictability': 694,\n",
       " 'future': 695,\n",
       " 'critical': 696,\n",
       " 'community': 697,\n",
       " 'country': 698,\n",
       " 'consider': 699,\n",
       " 'intelligent': 700,\n",
       " 'scotland': 701,\n",
       " 'line': 702,\n",
       " 'black': 703,\n",
       " 'hole': 704,\n",
       " 'enchanting': 705,\n",
       " 'terribly': 706,\n",
       " 'episodic': 707,\n",
       " 'spark': 708,\n",
       " 'imagination': 709,\n",
       " 'made': 710,\n",
       " 'exhilarating': 711,\n",
       " 'treat': 712,\n",
       " 'actors': 713,\n",
       " 'appealing': 714,\n",
       " 'idiotic': 715,\n",
       " 'absurdly': 716,\n",
       " 'sentimental': 717,\n",
       " 'effect': 718,\n",
       " 'any': 719,\n",
       " 'measure': 720,\n",
       " 'failure': 721,\n",
       " 'clarity': 722,\n",
       " 'sluggish': 723,\n",
       " 'kiss': 724,\n",
       " 'lazy': 725,\n",
       " 'deserve': 726,\n",
       " 'star': 727,\n",
       " 'wars': 728,\n",
       " 'drag': 729,\n",
       " 'biggest': 730,\n",
       " 'problem': 731,\n",
       " 'satin': 732,\n",
       " 'rouge': 733,\n",
       " 'lilia': 734,\n",
       " 'herself': 735,\n",
       " 'she': 736,\n",
       " 'cipher': 737,\n",
       " 'played': 738,\n",
       " 'actress': 739,\n",
       " 'smiles': 740,\n",
       " 'reveal': 741,\n",
       " 'inner': 742,\n",
       " 'quick': 743,\n",
       " 'cutting': 744,\n",
       " 'step': 745,\n",
       " 'goose': 746,\n",
       " 'dialogue': 747,\n",
       " 'sometimes': 748,\n",
       " 'kill': 749,\n",
       " 'work': 750,\n",
       " 'shallow': 751,\n",
       " 'entertainment': 752,\n",
       " 'remotely': 753,\n",
       " 'incisive': 754,\n",
       " 'qualify': 755,\n",
       " 'monsoon': 756,\n",
       " 'wedding': 757,\n",
       " 'serves': 758,\n",
       " 'mostly': 759,\n",
       " 'appetite': 760,\n",
       " 'bollywood': 761,\n",
       " 'films': 762,\n",
       " 'unfortunately': 763,\n",
       " 'contrived': 764,\n",
       " 'plotting': 765,\n",
       " 'woo': 766,\n",
       " 'instincts': 767,\n",
       " 'moral': 768,\n",
       " 'heart': 769,\n",
       " 'human': 770,\n",
       " 'goofball': 771,\n",
       " 'malkovich': 772,\n",
       " 'tries': 773,\n",
       " 'ripe': 774,\n",
       " 'manner': 775,\n",
       " 'lunacy': 776,\n",
       " 'kaufman': 777,\n",
       " 'rarely': 778,\n",
       " 'seem': 779,\n",
       " 'where': 780,\n",
       " 'characterizations': 781,\n",
       " 'complexity': 782,\n",
       " 'ironic': 783,\n",
       " 'exception': 784,\n",
       " 'credibility': 785,\n",
       " 'levels': 786,\n",
       " 'development': 787,\n",
       " 'quite': 788,\n",
       " 'frankly': 789,\n",
       " 'see': 790,\n",
       " 'why': 791,\n",
       " 'actor': 792,\n",
       " 'talent': 793,\n",
       " 'production': 794,\n",
       " 'again': 795,\n",
       " 'looked': 796,\n",
       " 'turned': 797,\n",
       " 'generally': 798,\n",
       " 'hour': 799,\n",
       " 'crowd': 800,\n",
       " 'ten': 801,\n",
       " 'indians': 802,\n",
       " 'meets': 803,\n",
       " 'friday': 804,\n",
       " 'th': 805,\n",
       " 'clean': 806,\n",
       " 'sober': 807,\n",
       " 'carpenter': 808,\n",
       " 'thing': 809,\n",
       " 'loaded': 810,\n",
       " 'inevitable': 811,\n",
       " 'boat': 812,\n",
       " 'obviously': 813,\n",
       " 'wasted': 814,\n",
       " 'including': 815,\n",
       " 'inconsequential': 816,\n",
       " 'central': 817,\n",
       " 'complex': 818,\n",
       " 'our': 819,\n",
       " 'men': 820,\n",
       " 'throwback': 821,\n",
       " 'fails': 822,\n",
       " 'many': 823,\n",
       " 'pay': 824,\n",
       " 'picture': 825,\n",
       " 'emerges': 826,\n",
       " 'surprisingly': 827,\n",
       " 'anemic': 828,\n",
       " 'disappointment': 829,\n",
       " 'title': 830,\n",
       " 'served': 831,\n",
       " 'dire': 832,\n",
       " 'warning': 833,\n",
       " 'wildly': 834,\n",
       " 'inconsistent': 835,\n",
       " 'emotional': 836,\n",
       " 'experience': 837,\n",
       " 'binoche': 838,\n",
       " 'sand': 839,\n",
       " 'century': 840,\n",
       " 'prose': 841,\n",
       " 'behind': 842,\n",
       " 'childlike': 843,\n",
       " 'smile': 844,\n",
       " 'stiff': 845,\n",
       " 'schmaltzy': 846,\n",
       " 'clumsily': 847,\n",
       " 'directed': 848,\n",
       " 'blend': 849,\n",
       " 'dumbed': 850,\n",
       " 'version': 851,\n",
       " 'college': 852,\n",
       " 'away': 853,\n",
       " 'sell': 854,\n",
       " 'apply': 855,\n",
       " 'medical': 856,\n",
       " 'imagine': 857,\n",
       " 'kevin': 858,\n",
       " 'trying': 859,\n",
       " 'irish': 860,\n",
       " 'accent': 861,\n",
       " 'doing': 862,\n",
       " 'comes': 863,\n",
       " 'across': 864,\n",
       " 'era': 865,\n",
       " 'poster': 866,\n",
       " 'mediocre': 867,\n",
       " 'tribute': 868,\n",
       " 'part': 869,\n",
       " 'fool': 870,\n",
       " 'himself': 871,\n",
       " 'femme': 872,\n",
       " 'fatale': 873,\n",
       " 'offers': 874,\n",
       " 'playing': 875,\n",
       " 'fair': 876,\n",
       " 'audience': 877,\n",
       " 'dealing': 878,\n",
       " 'dreams': 879,\n",
       " 'being': 880,\n",
       " 'told': 881,\n",
       " 'happened': 882,\n",
       " 'were': 883,\n",
       " 'clue': 884,\n",
       " 'everything': 885,\n",
       " 'possibly': 886,\n",
       " 'irresponsible': 887,\n",
       " 'released': 888,\n",
       " 'major': 889,\n",
       " 'studio': 890,\n",
       " 'banal': 891,\n",
       " 'unpleasant': 892,\n",
       " 'excuse': 893,\n",
       " 'appalling': 894,\n",
       " 'rip': 895,\n",
       " 'somehow': 896,\n",
       " 'bring': 897,\n",
       " 'together': 898,\n",
       " 'former': 899,\n",
       " 'credit': 900,\n",
       " 'media': 901,\n",
       " 'constructed': 902,\n",
       " 'issues': 903,\n",
       " 'whether': 904,\n",
       " 'compromise': 905,\n",
       " 'death': 906,\n",
       " 'orgasm': 907,\n",
       " 'won': 908,\n",
       " 'exceedingly': 909,\n",
       " 'latin': 910,\n",
       " 'hollywood': 911,\n",
       " 'resurrection': 912,\n",
       " 'halloween': 913,\n",
       " 'franchise': 914,\n",
       " 'dead': 915,\n",
       " 'pair': 916,\n",
       " 'poor': 917,\n",
       " 'comedic': 918,\n",
       " 've': 919,\n",
       " 'huge': 920,\n",
       " 'mess': 921,\n",
       " 'splendid': 922,\n",
       " 'looking': 923,\n",
       " 'expects': 924,\n",
       " 'special': 925,\n",
       " 'sci': 926,\n",
       " 'fi': 927,\n",
       " 'rehash': 928,\n",
       " 'produced': 929,\n",
       " 'grows': 930,\n",
       " 'decidedly': 931,\n",
       " 'sized': 932,\n",
       " 'pieces': 933,\n",
       " 'conceived': 934,\n",
       " 'fly': 935,\n",
       " 'lunch': 936,\n",
       " 'breaks': 937,\n",
       " 'voice': 938,\n",
       " 'howard': 939,\n",
       " 'appears': 940,\n",
       " 'free': 941,\n",
       " 'wanted': 942,\n",
       " 'best': 943,\n",
       " 'friend': 944,\n",
       " 'shouldn': 945,\n",
       " 'straight': 946,\n",
       " 'video': 947,\n",
       " 'science': 948,\n",
       " 'theater': 949,\n",
       " 'noble': 950,\n",
       " 'tradition': 951,\n",
       " 'hits': 952,\n",
       " 'sorority': 953,\n",
       " 'boys': 954,\n",
       " 'whose': 955,\n",
       " 'makers': 956,\n",
       " 'apparently': 957,\n",
       " 'believe': 958,\n",
       " 'cover': 959,\n",
       " 'then': 960,\n",
       " 'reasonably': 961,\n",
       " 'salton': 962,\n",
       " 'sea': 963,\n",
       " 'sequence': 964,\n",
       " 'ridiculous': 965,\n",
       " 'shoot': 966,\n",
       " 'em': 967,\n",
       " 'despite': 968,\n",
       " 'sparks': 969,\n",
       " 'welcome': 970,\n",
       " 'collinwood': 971,\n",
       " 'never': 972,\n",
       " 'catches': 973,\n",
       " 'fire': 974,\n",
       " 'left': 975,\n",
       " 'superficial': 976,\n",
       " 'snapshot': 977,\n",
       " 'however': 978,\n",
       " 'engaging': 979,\n",
       " 'enlightening': 980,\n",
       " 'inviting': 981,\n",
       " 'worrying': 982,\n",
       " 'frida': 983,\n",
       " 'spent': 984,\n",
       " 'exploring': 985,\n",
       " 'turning': 986,\n",
       " 'art': 987,\n",
       " 'superior': 988,\n",
       " 'ugly': 989,\n",
       " 'irritating': 990,\n",
       " 'without': 991,\n",
       " 'satirical': 992,\n",
       " 'hitting': 993,\n",
       " 'discernible': 994,\n",
       " 'target': 995,\n",
       " 'example': 996,\n",
       " 'type': 997,\n",
       " 'willing': 998,\n",
       " 'lend': 999,\n",
       " ...}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer.review_vocab._token_to_idx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Routine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "def make_train_state(args):\n",
    "    return {'stop_early': False,\n",
    "            'early_stopping_step': 0,\n",
    "            'early_stopping_best_val': 1e8,\n",
    "            'learning_rate': args.learning_rate,\n",
    "            'epoch_index': 0,\n",
    "            'train_loss': [],\n",
    "            'train_acc': [],\n",
    "            'val_loss': [],\n",
    "            'val_acc': [],\n",
    "            'test_loss': -1,\n",
    "            'test_acc': -1,\n",
    "            'model_filename': args.model_state_file}\n",
    "\n",
    "\n",
    "def update_train_state(args, model, train_state):\n",
    "    \"\"\"Handle the training state updates.\n",
    "\n",
    "    Components:\n",
    "     - Early Stopping: Prevent overfitting.\n",
    "     - Model Checkpoint: Model is saved if the model is better\n",
    "    \n",
    "    :param args: main arguments\n",
    "    :param model: model to train\n",
    "    :param train_state: a dictionary representing the training state values\n",
    "    :returns:\n",
    "        a new train_state\n",
    "    \"\"\"\n",
    "\n",
    "    # Save one model at least\n",
    "    if train_state['epoch_index'] == 0:\n",
    "        torch.save(model.state_dict(), train_state['model_filename'])\n",
    "        train_state['stop_early'] = False\n",
    "\n",
    "    # Save model if performance improved\n",
    "    elif train_state['epoch_index'] >= 1:\n",
    "        loss_tm1, loss_t = train_state['val_loss'][-2:]\n",
    "         \n",
    "        # If loss worsened\n",
    "        if loss_t >= loss_tm1:\n",
    "            # Update step\n",
    "            train_state['early_stopping_step'] += 1\n",
    "        # Loss decreased\n",
    "        else:\n",
    "            # Save the best model\n",
    "            if loss_t < train_state['early_stopping_best_val']:\n",
    "                torch.save(model.state_dict(), train_state['model_filename'])\n",
    "                train_state['early_stopping_best_val'] = loss_t\n",
    "\n",
    "            # Reset early stopping step\n",
    "            train_state['early_stopping_step'] = 0\n",
    "\n",
    "        # Stop early ?\n",
    "        train_state['stop_early'] = \\\n",
    "            train_state['early_stopping_step'] >= args.early_stopping_criteria\n",
    "\n",
    "    return train_state\n",
    "\n",
    "\n",
    "def compute_accuracy(y_pred, y_target):\n",
    "    _, y_pred_indices = y_pred.max(dim=1)\n",
    "    n_correct = torch.eq(y_pred_indices, y_target).sum().item()\n",
    "    return n_correct / len(y_pred_indices) * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "code_folding": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fc26e967962542bdbcd86b3bf3b5abc0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='training routine', style=ProgressStyle(description_width="
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3aca46aa3ff34f4980b025ca2a6d3dc3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='split=train', max=116.0, style=ProgressStyle(description_"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "04dca7b785ea4776a463482b830cd47f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='split=val', max=24.0, style=ProgressStyle(description_wid"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "classifier = classifier.to(args.device)\n",
    "dataset.class_weights = dataset.class_weights.to(args.device)\n",
    "    \n",
    "loss_func = nn.CrossEntropyLoss(dataset.class_weights)\n",
    "optimizer = optim.Adam(classifier.parameters(), lr=args.learning_rate)\n",
    "scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer=optimizer,\n",
    "                                           mode='min', factor=0.5,\n",
    "                                           patience=1)\n",
    "\n",
    "train_state = make_train_state(args)\n",
    "\n",
    "epoch_bar = tqdm(desc='training routine', total=args.num_epochs, position=0)\n",
    "\n",
    "dataset.set_split('train')\n",
    "train_bar = tqdm(desc='split=train', total=dataset.get_num_batches(args.batch_size), position=1, leave=True)\n",
    "\n",
    "dataset.set_split('val')\n",
    "val_bar = tqdm(desc='split=val', total=dataset.get_num_batches(args.batch_size), position=1, leave=True)\n",
    "\n",
    "try:\n",
    "    for epoch_index in range(args.num_epochs):\n",
    "        train_state['epoch_index'] = epoch_index\n",
    "\n",
    "        # Iterate over training dataset\n",
    "\n",
    "        # setup: batch generator, set loss and acc to 0, set train mode on\n",
    "        dataset.set_split('train')\n",
    "        batch_generator = generate_batches(dataset, \n",
    "                                           batch_size=args.batch_size, \n",
    "                                           device=args.device)\n",
    "        running_loss = 0.0\n",
    "        running_acc = 0.0\n",
    "        classifier.train()\n",
    "\n",
    "        for batch_index, batch_dict in enumerate(batch_generator):\n",
    "            # the training routine is these 5 steps:\n",
    "\n",
    "            # --------------------------------------    \n",
    "            # step 1. zero the gradients\n",
    "            optimizer.zero_grad()\n",
    "           \n",
    "            # step 2. compute the output\n",
    "            y_pred = classifier(x_in=batch_dict['x_data'], \n",
    "                                x_lengths=batch_dict['x_length'])\n",
    "\n",
    "            # step 3. compute the loss\n",
    "            loss = loss_func(y_pred, batch_dict['y_target'])\n",
    "    \n",
    "            running_loss += (loss.item() - running_loss) / (batch_index + 1)\n",
    "\n",
    "            # step 4. use loss to produce gradients\n",
    "            loss.backward()\n",
    "\n",
    "            # step 5. use optimizer to take gradient step\n",
    "            optimizer.step()\n",
    "            # -----------------------------------------\n",
    "            # compute the accuracy\n",
    "            acc_t = compute_accuracy(y_pred, batch_dict['y_target'])\n",
    "            running_acc += (acc_t - running_acc) / (batch_index + 1)\n",
    "\n",
    "            # update bar\n",
    "            train_bar.set_postfix(loss=running_loss, acc=running_acc, epoch=epoch_index)\n",
    "            train_bar.update()\n",
    "\n",
    "        train_state['train_loss'].append(running_loss)\n",
    "        train_state['train_acc'].append(running_acc)\n",
    "\n",
    "        # Iterate over val dataset\n",
    "\n",
    "        # setup: batch generator, set loss and acc to 0; set eval mode on\n",
    "\n",
    "        dataset.set_split('val')\n",
    "        batch_generator = generate_batches(dataset, \n",
    "                                           batch_size=args.batch_size, \n",
    "                                           device=args.device)\n",
    "        running_loss = 0.\n",
    "        running_acc = 0.\n",
    "        classifier.eval()\n",
    "\n",
    "        for batch_index, batch_dict in enumerate(batch_generator):\n",
    "            # compute the output\n",
    "            y_pred = classifier(x_in=batch_dict['x_data'], \n",
    "                                x_lengths=batch_dict['x_length'])\n",
    "\n",
    "            # step 3. compute the loss\n",
    "            loss = loss_func(y_pred, batch_dict['y_target'])\n",
    "            running_loss += (loss.item() - running_loss) / (batch_index + 1)\n",
    "\n",
    "            # compute the accuracy\n",
    "            acc_t = compute_accuracy(y_pred, batch_dict['y_target'])\n",
    "            running_acc += (acc_t - running_acc) / (batch_index + 1)\n",
    "            val_bar.set_postfix(loss=running_loss, acc=running_acc, epoch=epoch_index)\n",
    "            val_bar.update()\n",
    "\n",
    "        train_state['val_loss'].append(running_loss)\n",
    "        train_state['val_acc'].append(running_acc)\n",
    "\n",
    "        train_state = update_train_state(args=args, model=classifier, \n",
    "                                         train_state=train_state)\n",
    "\n",
    "        scheduler.step(train_state['val_loss'][-1])\n",
    "\n",
    "        train_bar.n = 0\n",
    "        val_bar.n = 0\n",
    "        epoch_bar.update()\n",
    "\n",
    "        if train_state['stop_early']:\n",
    "            break\n",
    "            \n",
    "except KeyboardInterrupt:\n",
    "    print(\"Exiting loop\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "acc = train_state['train_acc']\n",
    "val_acc = train_state['val_acc']\n",
    "loss = train_state['train_loss']\n",
    "val_loss = train_state['val_loss']\n",
    "\n",
    "epochs = range(1, len(acc) + 1)\n",
    "\n",
    "# \"bo\" is for \"blue dot\"\n",
    "plt.plot(epochs, loss, 'bo', label='Training loss')\n",
    "# b is for \"solid blue line\"\n",
    "plt.plot(epochs, val_loss, 'b', label='Validation loss')\n",
    "plt.title('Training and validation loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.clf()   # clear figure\n",
    "\n",
    "plt.plot(epochs, acc, 'bo', label='Training acc')\n",
    "plt.plot(epochs, val_acc, 'b', label='Validation acc')\n",
    "plt.title('Training and validation accuracy')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute the loss & accuracy on the test set using the best available model\n",
    "\n",
    "classifier.load_state_dict(torch.load(train_state['model_filename']))\n",
    "\n",
    "classifier = classifier.to(args.device)\n",
    "dataset.class_weights = dataset.class_weights.to(args.device)\n",
    "loss_func = nn.CrossEntropyLoss(dataset.class_weights)\n",
    "\n",
    "dataset.set_split('test')\n",
    "batch_generator = generate_batches(dataset, \n",
    "                                   batch_size=args.batch_size, \n",
    "                                   device=args.device)\n",
    "running_loss = 0.\n",
    "running_acc = 0.\n",
    "classifier.eval()\n",
    "\n",
    "y_pred_list = []         # store predicted values for confusion matrix\n",
    "y_rating_list = []  # ground truth value\n",
    "\n",
    "for batch_index, batch_dict in enumerate(batch_generator):\n",
    "    # compute the output\n",
    "    y_pred =  classifier(batch_dict['x_data'],\n",
    "                         x_lengths=batch_dict['x_length'])\n",
    "\n",
    "    # store predicted values and ground truth values for calculating confusion matrix\n",
    "    y_pred_list.extend(y_pred.max(dim=1)[1].cpu().numpy())\n",
    "    y_rating_list.extend(batch_dict['y_target'].cpu().numpy())\n",
    "    \n",
    "    # compute the loss\n",
    "    loss = loss_func(y_pred, batch_dict['y_target'])\n",
    "    loss_t = loss.item()\n",
    "    running_loss += (loss_t - running_loss) / (batch_index + 1)\n",
    "\n",
    "    # compute the accuracy\n",
    "    acc_t = compute_accuracy(y_pred, batch_dict['y_target'])\n",
    "    running_acc += (acc_t - running_acc) / (batch_index + 1)\n",
    "\n",
    "train_state['test_loss'] = running_loss\n",
    "train_state['test_acc'] = running_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 0.5486391091346742;\n",
      "Test Accuracy: 72.7842741935484\n"
     ]
    }
   ],
   "source": [
    "print(\"Test loss: {};\".format(train_state['test_loss']))\n",
    "print(\"Test Accuracy: {}\".format(train_state['test_acc']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['negative', 'positive']\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "rating_classes = []\n",
    "for i in range(len(dataset._vectorizer.rating_vocab)):\n",
    "    rating_classes.append(dataset._vectorizer.rating_vocab.lookup_index(i))\n",
    "print(rating_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True       negative  positive\n",
      "Predicted                    \n",
      "negative        638       274\n",
      "positive        161       525\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "cm = confusion_matrix(y_rating_list, y_pred_list)\n",
    "cm_df = pd.DataFrame(cm.T, index=rating_classes, columns=rating_classes)\n",
    "cm_df.index.name = 'Predicted'\n",
    "cm_df.columns.name = 'True'\n",
    "print(cm_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      0.80      0.75       799\n",
      "           1       0.77      0.66      0.71       799\n",
      "\n",
      "    accuracy                           0.73      1598\n",
      "   macro avg       0.73      0.73      0.73      1598\n",
      "weighted avg       0.73      0.73      0.73      1598\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_rating_list, y_pred_list))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_sentiment(review, classifier, vectorizer):\n",
    "    vectorized_review, vec_length = vectorizer.vectorize(review)\n",
    "    vectorized_review = torch.tensor(vectorized_review).unsqueeze(dim=0)\n",
    "    vec_length = torch.tensor([vec_length], dtype=torch.int64)\n",
    "    \n",
    "    result = classifier(vectorized_review, vec_length, apply_softmax=True)\n",
    "    probability_values, indices = result.max(dim=1)\n",
    "    \n",
    "    index = indices.item()\n",
    "    prob_value = probability_values.item()\n",
    "\n",
    "    predicted_rating = vectorizer.rating_vocab.lookup_index(index)\n",
    "\n",
    "    return {'sentiment': predicted_rating, 'probability': prob_value, 'review': review}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'sentiment': 'negative', 'probability': 0.7948821187019348, 'review': 'i went here for restaurant week . the restaurant is not that nice inside the wait staff was not very professional . i ordered the chop salad . it appeared to be on leaf on lettuce chopped up no avocado as stated on menu blah . my steak was ordered medium came to table well done so it was sent back . the bread was not made fresh there tasted like a roll from fry s . dessert was okay . much better places out there for much cheaper . i won t be going back !'}\n"
     ]
    }
   ],
   "source": [
    "# review = input(\"Enter a review: \")\n",
    "review = \"i went here for restaurant week . the restaurant is not that nice inside the wait staff was not very professional . i ordered the chop salad . it appeared to be on leaf on lettuce chopped up no avocado as stated on menu blah . my steak was ordered medium came to table well done so it was sent back . the bread was not made fresh there tasted like a roll from fry s . dessert was okay . much better places out there for much cheaper . i won t be going back !\"\n",
    "classifier = classifier.to(\"cpu\")\n",
    "print(predict_sentiment(review, classifier, vectorizer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "toc": {
   "colors": {
    "hover_highlight": "#DAA520",
    "running_highlight": "#FF0000",
    "selected_highlight": "#FFD700"
   },
   "moveMenuLeft": true,
   "nav_menu": {
    "height": "120px",
    "width": "252px"
   },
   "navigate_menu": true,
   "number_sections": true,
   "sideBar": true,
   "threshold": "5",
   "toc_cell": false,
   "toc_section_display": "block",
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
